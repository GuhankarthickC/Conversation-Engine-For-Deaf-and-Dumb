{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuhankarthickC/Conversation-Engine-For-Deaf-and-Dumb/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5DSdedTdaOk"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import models"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HvvSVibdaOu",
        "outputId": "33bb259e-8333-4217-90a1-ad9a46a33c93"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwlj_9p8daOv",
        "outputId": "7081d544-4111-4544-dec3-19425161f727"
      },
      "source": [
        "x_train = train_datagen.flow_from_directory('gdrive/My Drive/training_set/', target_size=(64,64), batch_size=300, class_mode='categorical',  color_mode = \"grayscale\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15759 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yvVcBEedaOw",
        "outputId": "a802ad38-1cf9-412e-b4c2-0b048fc242c8"
      },
      "source": [
        "x_train.class_indices"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZJL42YdaOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d629c30-5de4-40d7-f561-c95ec3f18ef9"
      },
      "source": [
        "x_test = test_datagen.flow_from_directory('gdrive/My Drive/test_set/', target_size=(64,64), batch_size=300, class_mode='categorical',  color_mode = \"grayscale\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1310 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZDdsP3rdaOx"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSSswj8VdaOx"
      },
      "source": [
        "model.add(Convolution2D(32, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvfO8BNFdaOy"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnT-eHrMdaOy"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ7-aTy8daOz"
      },
      "source": [
        "model.add(Convolution2D(64, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ1kmBHhdaO0"
      },
      "source": [
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wap_36J9daO1"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydP5JJo-daO1"
      },
      "source": [
        "model.add(Convolution2D(128, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj9GZ86FdaO2"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK0UB-qzdaO3"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8eQ6PhdaO3"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-7at7EPdaO3"
      },
      "source": [
        "model.add(Dense(units=512, activation='relu'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N1qJtZEdaO4"
      },
      "source": [
        "model.add(Dense(units=9, activation='softmax'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eqtQgCVdaO4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76FgFA11daO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855e1b9f-2fc7-4941-a5a4-42d809661306"
      },
      "source": [
        "model.fit(x_train, steps_per_epoch=24, epochs=3, validation_data=x_test, validation_steps=40)\n",
        "\n",
        "#steps_per_epoch = no. of train images//batch size"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.6990 - accuracy: 0.3999  WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
            "24/24 [==============================] - 4674s 196s/step - loss: 1.6790 - accuracy: 0.4079 - val_loss: 0.6903 - val_accuracy: 0.8573\n",
            "Epoch 2/3\n",
            "24/24 [==============================] - 2067s 86s/step - loss: 0.3125 - accuracy: 0.9073\n",
            "Epoch 3/3\n",
            "24/24 [==============================] - 1081s 45s/step - loss: 0.1249 - accuracy: 0.9579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1564347610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoMjpE_LdaO5"
      },
      "source": [
        "model.save('aslpng1.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7n3gzbidaO5"
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp_mzGMZdaO5"
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('aslpng1.h5')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCvIowMUdaO5"
      },
      "source": [
        "from skimage.transform import resize\n",
        "def detect(frame):\n",
        "        img = resize(frame,(64,64,1))\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        if(np.max(img)>1):\n",
        "            img = img/255.0\n",
        "        prediction = model.predict(img)\n",
        "        print(prediction)\n",
        "        prediction = model.predict_classes(img)\n",
        "        print(prediction)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "IzmFaZ96dCTR",
        "outputId": "be8ab9e6-8f98-4f7b-a6f4-1a67c7203f3f"
      },
      "source": [
        "frame=cv2.imread(r\"gdrive/My Drive/test_set/E/1.png\")\n",
        "data = detect(frame)\n",
        "plt.figure()\n",
        "plt.imshow(frame)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.1239457e-03 5.0207583e-04 1.3793156e-05 1.9523341e-08 9.9226004e-01\n",
            "  8.0711476e-07 1.9624451e-07 5.1811492e-07 9.8692486e-05]]\n",
            "[4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD7CAYAAAACYaMOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXNklEQVR4nO3dfaxdVZnH8e+PAsLwjtVSoFBG6lBMxoIVS2CcClFb4lhJlMAYqaaxmJQXgxMBJ45ghgQTBd8I8SoMJWEoRUEagtTSgRgT3lqs0HKLrbxIS6HyzqBCe+8zf+x975xz7ts+9+xz9ln3/j5k5669zz5nP+XcPl1r7bX2UkRgZpaqPaoOwMysFU5iZpY0JzEzS5qTmJklzUnMzJLmJGZmSWspiUlaIOlJSVslXVpWUGZmRWm848QkTQH+AHwc2AY8ApwTEU+UF56Z2ej2bOG9JwFbI+IpAEkrgEXAiElMkkfWmrVZRKiV93/yY/vFy6/0FTp3/WNvr46IBa1cr1WtJLEjgOdq9rcBH2ktHDOr2suv9PHw6qMKnTtl+papo70uaQZwEzANCKAnIn4g6XLgy8Cf81O/ERF35++5DFgC9AEXRsTq0a7RShIrRNJSYGm7r2Nm5Qign/6yPm438LWIeFTSAcB6SWvy166JiO/WnizpeOBs4APA4cC9kt4fESNWDVtJYtuBGTX7R+bH6kRED9CTB+jmpFmXC4JdI+eM5j4rYgewIy+/KamXrBU3kkXAioh4G3ha0layrqsHRnpDK3cnHwFmSTpG0t5k2XNVC59nZl2iv+B/zZA0EzgBeCg/dL6kxyTdIOmQ/Nhw3VSjJb3xJ7GI2A2cD6wGeoGVEbFpvJ9nZt0hCPqi2AZMlbSuZhu260jS/sAvgK9GxBvAdcD7gDlkNbXvjTfelvrE8o64u1v5DDPrPv0U7vl5KSLmjnaCpL3IEtjNEXE7QES8WPP6T4G78t1C3VS1PGLfzOoE0EcU2sYiScD1QG9EXF1zfHrNaWcCG/PyKuBsSe+SdAwwC3h4tGu0/e6kmaWniZrYWE4BvgA8LmlDfuwbwDmS5pDlzGeA8wAiYpOklWTjTXcDy0a7MwlOYmbWIIBdJT3xOSJ+Cww3+HbEbqiIuBK4sug1nMTMrE4UbCp2CycxM6sX0JdODnMSM7N62Yj9dDiJmVkD0TdsN1Z3chIzszpZx76TmJklKhsn5iRmZgnrd03MzFLlmpiZJS0QfQnNSHQSM7Mh3Jw0s2QF4p2YUnUYhTmJmVmdbLCrm5NmljB37JtZsiJEX7gmZmYJ63dNzMxSlXXsp5Ma0onUzDrCHftmlrw+jxMzs1R5xL6ZJa/fdyfNLFXZBHAnMTNLVCB2JTTtaMx0K+kGSTslbaw5dqikNZK25D8PaW+YZtYpEdAXexTaukGRKG4EFjQcuxRYGxGzgLX5vplNCKK/4NYNxkxiEfEb4JWGw4uA5Xl5OfCZkuMys4oEadXExtsnNi0iduTlF4BpJcVjZl1gUnXsR0RIGnGpTUlLgaWtXsfMOiPQpHgo4ouSpkfEDknTgZ0jnRgRPUAPwGjJzoqLaP5/4+zZs+v2N2/eXFY4NsFkS7alM3BhvHXGVcDivLwYuLOccMysetniuUW2bjBmupV0CzAfmCppG/At4CpgpaQlwLPAWe0M0sw6J5hgI/Yj4pwRXjq95FjMrEt0Sy2riHQavpPMmWeeOVi+/fbbW/683t7eun2p2C/pePrfGhW9lnWHCE2smpiZTS5Zx/4EmnZkZpONShvsKmmGpPskPSFpk6SL8uPDTl1U5oeStkp6TNKJY13DNbESNDbVaj399NN1+2eccUahzyyjCTma2mbi9OnT6157/vnnS73W66+/Plg+6KCDSv1sK1/WsV9aF8Bu4GsR8aikA4D1ktYAXySbuniVpEvJpi5eAiwEZuXbR4Dr8p8jck3MzIboY49C21giYkdEPJqX3wR6gSMYeeriIuCmyDwIHJyPRR2Ra2JmVqddI/YlzQROAB5i5KmLRwDP1bxtW35sByNwEjOzIZpYKGSqpHU1+z35LJ06kvYHfgF8NSLeqL1jPdbUxbE4iY1T0aEHxx133Ijvaxx6UMZwhvHYsWPEf+RKceCBBw6Wzz333LrXbrrpprZe25oXAbv6CyexlyJi7mgnSNqLLIHdHBEDnb0jTV3cDsyoefuR+bERuU/MzOpkzck9Cm1jUfYv9fVAb0RcXfPSSFMXVwHn5ncp5wGv1zQ7h+WamJkNUeKI/VOALwCPS9qQH/sGI09dvBs4A9gK/AX40lgXcBJrQtnNvaqaj1Vavnx53f6sWbMGy9/85jc7HY4No8whFhHxWxgxIw6ZuhjZX4plzVzDSczMGnjakZklrluen1+Ek9goJmNzr9P23NO/gt0muzuZztxJ/waZWZ3J8nhqM5vA3Jw0s2SVPAG87ZzEGhx22GFVhzCp7L///oPl/fbbr+61t956q9PhWM53J80sWRFit5OYmaUspeakOjmMIIV1Jz2sontcfvnlg+UrrriiukASE9FaBjr4uPfGP/+s2AJmq/7p2vVjTQBvN9fEzGyIlGpiTmJmVsfjxMwseR4nZlaC2j6x1atXD5YffPDBCqKZPCJgd/GHIlZuzEibXXLJzNLXHyq0dYMi6XZgyaXjgXnAMknHky2xtDYiZgFr830zS9xAn1gqSWzM5mT+aNgdeflNSbVLLs3PT1sO3E+2bpxZ6R544IHB8sKFC+teu+eeezodzoTX4iiNjmqqT6zgkktmlrgJ2bE/3iWXJC0FlrYaqJl1RsQEHCfW5JJLdfI16Hryz/FweLOuJ/oSujs5ZhIrsOTSVdQvuZSUX/3qV1WHYNZ1JlqfWLNLLplZwibc88SaXXLJzBIXWb9YKjxi38yGmJB3J81scoiJ1rFvZpOPm5NmlrSJdnfSzCaRCCcxM0vchBpiYWaTj/vEzDroqKOOGiz/6U9/qjCSiSEQ/b47aWYpS6gi5iRmZg3csZ+WBQsWVB2CNalx0v7JJ588WHZzsiQJVcXSafiaWcdEqNA2Fkk3SNopaWPNscslbZe0Id/OqHntMklbJT0p6ZNFYp30NTEzqxdAf39pzckbgR8DNzUcvyYivlt7IF+742zgA8DhwL2S3h8RfaNdwDUxM6sXQKjYNtZHRfwGeKXglRcBKyLi7Yh4GtgKnDTWm1wTs+Rt2bKl6hAmnA6MEztf0rnAOrLV1F4lW4CodlHRbfmxUbkmZmZDRcENpkpaV7MVWU/jOuB9wByyldS+10qoromZWYNinfa5lyJibjOfHhEvDl5J+ilwV767HZhRc+qR+bFRuSZmyXv55ZcHNytJ8ZpY0/KFhQacCQzcuVwFnC3pXZKOAWYBD4/1ea6JmVm9gCjp7qSkW8gW2Z4qaRvwLWC+pDnZlXgGOA8gIjZJWgk8AewGlo11ZxKcxMxsWOUksYg4Z5jD149y/pXAlc1cw0nMkrNw4cKqQ5j4Ehqx7yRmZkM5iZlZsgYGuybCSczMhvBDEc0sbeXNnWy7MceJSdpH0sOSfi9pk6Qr8uPHSHoon3F+q6S92x+umXWCotjWDYoMdn0bOC0iPkg2TWCBpHnAd8hmoh8LvAosaV+YZtYxRQe6dkkSG7M5GREB/G++u1e+BXAa8K/58eXA5WRzopJyzz331O37IYndLxo6bObNmzdYfvDBBxtPt6YVe0JFtyg07UjSFEkbgJ3AGuCPwGsRsTs/pdBsczNLxESqiQHkQ//nSDoYuAM4rugF8lntRWa2m1m36K86gOKaujsZEa9Jug84GThY0p55bWzE2eYR0QP0AEjd0hVoZiNKbJxYkbuT78lrYEjaF/g40AvcB3w2P20xcGe7gjSzzkrp7mSRmth0YLmkKWRJb2VE3CXpCWCFpP8EfscokzrNLDFdkqCKKHJ38jHghGGOP0WB51+bmbWTR+xb8jysonzd0lQswknMzOoFSU07chIzs6FcEzOzlLk5aWZpcxIzs6Q5iZlZqrppIGsRTmKWHCmdO2fJ8t1JM0uZa2JmljYnsXQ0rmHY+MA9s0nHfWJmljwnMTNLmRJ6KGKhx1ObmXUr18QsOR/60Ifq9hsXe7ESuDlpZslyx76ZJS+hJKZODilIYaEQD7FIj0fw14tobZWPfQ6fETO/fHGhc5/89sXrI2JuK9drlWtiZlZHpHV30knMzOol1ifmIRZmNlRJK4BLukHSTkkba44dKmmNpC35z0Py45L0Q0lbJT0m6cQioTqJmdlQJSUx4EZgQcOxS4G1ETELWJvvAywEZuXbUuC6IhdwEjOzIcpaPDcifgO80nB4EbA8Ly8HPlNz/KbIPAgcLGn6WNdwEjOzocqriQ1nWkTsyMsvANPy8hHAczXnbcuPjcod+w2WLVs2WL722msrjMRGsnLlyqpDmNiiqbuTUyWtq9nviYiewpeKiFaHXhVOYpKmAOuA7RHxKUnHACuAdwPrgS9ExDutBGNmXaJ4WnlpHOPEXpQ0PSJ25M3Fnfnx7cCMmvOOzI+Nqpnm5EVAb83+d4BrIuJY4FVgSROfZWZdrKw+sRGsAhbn5cXAnTXHz83vUs4DXq9pdo4Sa4ER6pKOJOuAuxK4GPgX4M/AYRGxW9LJwOUR8ckxPieh0Scevd+tPEJ/dK2O2N/3sBlx7OeLjdjfePXoI/Yl3QLMB6YCLwLfAn4JrASOAp4FzoqIV5R9sT8mu5v5F+BLEbFuuM+tVbQ5+X3g68AB+f67gdciYne+X6gDzswS0Fqnff1HRZwzwkunD3NuAMuGOXdUYzYnJX0K2BkR65v98Pz9SyWta+j8M7MuJdrenCxVkZrYKcCnJZ0B7AMcCPyAbAzHnnltbMQOuPxORQ+k15w0m6xS+ps6ZhKLiMuAywAkzQf+LSI+L+k24LNkdyhrO+fMSrdunSvyHZVQEmtlsOslwMWStpL1kV1fTkhmVrn2DnYtVVODXSPifuD+vPwUcFL5IZlZpbqov6sIj9gfxfPPP1+3f/jhh1cUiX34wx+uOoTJxUnMzFLmhyKaWdLcnJwg3njjjbp9Nyerc/bZZw+WV6xYUWEkk0AXddoX4SRmZkM5iZlZqgZG7KfCSczMhlB/OlnMScyS4CeKdJD7xMwsdW5OmlnanMQmhtmzZ9ftu0lTnVtvvbXqECYV18TMLG1OYmaWrOZWO6qck5iZ1fE4MTNLX0L9v05iZjaEa2Jmli4PdjUr3+c+97nB8m233VZhJJODO/bNLGlOYmaWrsAd+xPVs88+O1g++uijK4xk8tljj1YW5rJmuWPfzNLmJGZmqfJgVzNLW4QfijhRzZw5c7DsJ1p0lp9i0WEJ/XoXSmKSngHeBPqA3RExV9KhwK3ATOAZ4KyIeLU9YZpZJ6XUnGzmls/HImJORMzN9y8F1kbELGBtvm9mqQugP4ptXaCV5uQiYH5eXg7cD1zSYjzJ+Nvf/jZY3meffSqMZOL6yle+UnUIk1d35KdCitbEAvi1pPWSlubHpkXEjrz8AjCt9OjMrBKKYluhz5KekfS4pA2S1uXHDpW0RtKW/Och4421aBI7NSJOBBYCyyR9tPbFyHq5h/0jSVoqad1A8GbW/dQfhbYmtK07qlASi4jt+c+dwB3AScCLkqYD5D93jvDenoiYWxO8mXWzaGIbv0Vk3VDkPz8z3g8aM4lJ2k/SAQNl4BPARmAVsDg/bTFw53iDSNG+++47uFl77Ny5c3CzzskGu0ahraC2dkcV6difBtwhaeD8/46IeyQ9AqyUtAR4FjhrvEGYWZcp/hSLqQ1dRT0R0dNwzqkRsV3Se4E1kjbXvhgRIY1/UMeYSSwingI+OMzxl4HTx3thM+teTdSyXhqrq6i2O0pSXXdUROwYrTuqCI/Yt651xx13VB3C5FTik13zLqg9IuLNmu6ob/P/3VFX0WJ3lJOYmTUode5k27ujnMTMbKiS5gZ3ojvKSczM6nnx3MmncZjFX//614oiMStJQk9pcRIzs6HSyWFOYmY2lPrTaU86iZWg9okWNn4PPfRQ1SEY5I/iqTqI4pzEzKyOaGpKUeWcxMxsKCexye1HP/rRYPmCCy6oMJLud//99w+WV69eXV0gVs9JzMyS5T4xM0ud706aWcLCzcnJ7sILLxwsu09sdPPnzx8su0+sSwROYmaWuHRak05iZjaUx4mZjcNVV11VdQg2wEnMzJIVAX3ptCedxMxsKNfEzCxpTmI2YPbs2XX7vb29FUViVlAA5T1jv+2cxMysQUC4T8zMUhW4Y9/MEpdQn9geRU6SdLCkn0vaLKlX0smSDpW0RtKW/Och7Q7WzDokotjWBQolMeAHwD0RcRzZGnK9wKXA2oiYBazN980seQUTWJcksTGbk5IOAj4KfBEgIt4B3pG0CJifn7YcuB+4pB1Bpmzz5s1Vh5CMaPhLka8abZ0WQEKP4ilSEzsG+DPwX5J+J+lnkvYDpkXEjvycF8iWKzeziSChmliRJLYncCJwXUScALxFQ9Mxsn9Ch/0TSVoqaZ2kda0Ga2adkE87KrJ1gSJJbBuwLSIG1tP6OVlSe1HSdID8587h3hwRPRExNyLmlhGwmbVZQER/oa0bjJnEIuIF4DlJ/5AfOh14AlgFLM6PLQbubEuEZtZ5/VFs6wJFx4ldANwsaW/gKeBLZAlwpaQlwLPAWe0J0cw6rkv6u4oolMQiYgMwXHPw9HLDMbPKRSR1d9Ij9jts7733Hiy/8847FUZiNoqJVhMzs8kkiL6+qoMozEnMzOol9iieotOOzGwyif5iWwGSFkh6UtJWSaVPT3RNrMN27dpVdQjJOO+88wbLP/nJTyqMZHIJIEqqiUmaAlwLfJxszOkjklZFxBOlXADXxMysUUSZNbGTgK0R8VQ+73oFsKjMcF0TM7MhSuzYPwJ4rmZ/G/CRsj4cOp/EXiIbGDs1L1ep8hjypzRUHkfOcdRLNY6jW73gm7y6+t74+dSCp+/TMC+6JyJ6Wo2hGR1NYhHxHgBJ66qeS9kNMTgOx9GNcUTEghI/bjswo2b/yPxYadwnZmbt9AgwS9Ix+bTFs8nmXZfGfWJm1jYRsVvS+cBqYApwQ0RsKvMaVSWxjraZR9ANMYDjaOQ46nVLHOMWEXcDd7fr89X4SGAzs5S4T8zMktbRJNbu6QejXPcGSTslbaw51vEl5yTNkHSfpCckbZJ0URWxSNpH0sOSfp/HcUV+/BhJD+Xfz615R2zbSZqSr99wV1VxSHpG0uOSNgwMGajod8TLIzapY0msZvrBQuB44BxJx3fo8jcCjbeNq1hybjfwtYg4HpgHLMv/H3Q6lreB0yLig8AcYIGkecB3gGsi4ljgVWBJm+MYcBHZMoADqorjYxExp2ZIQxW/I14esVkR0ZENOBlYXbN/GXBZB68/E9hYs/8kMD0vTwee7FQsNTHcSTanrLJYgL8DHiUbRf0SsOdw31cbr38k2V/M04C7AFUUxzPA1IZjHf1egIOAp8n7qquKI7Wtk83J4aYfHNHB6zeqdMk5STOBE4CHqoglb8JtIFvgZQ3wR+C1iNidn9Kp7+f7wNeBgYl4764ojgB+LWm9pKX5sU5/L14ecRzcsc/oS861g6T9gV8AX42IN6qIJSL6ImIOWU3oJOC4dl+zkaRPATsjYn2nrz2MUyPiRLLujmWSPlr7Yoe+l5aWR5ysOpnE2j79oEmFlpwrm6S9yBLYzRFxe5WxAETEa8B9ZM22gyUNjB3sxPdzCvBpSc+QPd3gNLI+oU7HQURsz3/uBO4gS+yd/l5aWh5xsupkEmv79IMmdXzJOWUzvq8HeiPi6qpikfQeSQfn5X3J+uV6yZLZZzsVR0RcFhFHRsRMst+H/4mIz3c6Dkn7STpgoAx8AthIh7+X8PKI49PJDjjgDOAPZP0v/97B694C7AB2kf1rt4Ss72UtsAW4Fzi0A3GcStYUeAzYkG9ndDoW4B+B3+VxbAT+Iz/+98DDwFbgNuBdHfyO5gN3VRFHfr3f59umgd/Nin5H5gDr8u/ml8AhVcSR0uYR+2aWNHfsm1nSnMTMLGlOYmaWNCcxM0uak5iZJc1JzMyS5iRmZklzEjOzpP0fDs9wh/e8HPsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5HxZkSmpCf",
        "outputId": "09f954ce-a174-48b7-c104-afd67bdcb318"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Downloading https://files.pythonhosted.org/packages/44/31/4494ecac89677d3c839d079363ab655c4751764803ddcd22bcc37f6d32f8/gTTS-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8DlO2Tfmrzd"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from flask import Flask, render_template, Response\n",
        "import tensorflow as tf\n",
        "from gtts import gTTS #to convert text to speech\n",
        "global graph\n",
        "global writer\n",
        "from skimage.transform import resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAoFXsHLmupY",
        "outputId": "e0ea3c9f-cd45-4740-d78f-89f18e8d6a4c"
      },
      "source": [
        "graph = tf.Graph()\n",
        "writer = None\n",
        "\n",
        "model = load_model('aslpng1.h5')\n",
        "\n",
        "vals = ['A', 'B','C','D','E','F','G','H','I']\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs = cv2.VideoCapture(0) #triggers the local camera\n",
        "\n",
        "pred=\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] accessing video stream...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLbnki7mxue"
      },
      "source": [
        "def detect(frame):\n",
        "        img = resize(frame,(64,64,1))\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        if(np.max(img)>1):\n",
        "            img = img/255.0\n",
        "        with graph.as_default():\n",
        "                prediction = model.predict_classes(img)\n",
        "        print(prediction)\n",
        "        pred=vals[prediction[0]]\n",
        "        print(pred)\n",
        "        return pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pEY38npnWq5"
      },
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2MfrGHTnbOQ"
      },
      "source": [
        "def gen():\n",
        "        while True:\n",
        "            # read the next frame from the file\n",
        "            (grabbed, frame) = vs.read()\n",
        "            \n",
        "            # if the frame was not grabbed, then we have reached the end\n",
        "            # of the stream\n",
        "            if not grabbed:\n",
        "                break\n",
        "            \n",
        "            data = detect(frame)\n",
        "            # output frame\n",
        "            text = \"It indicates \"+data\n",
        "            cv2.putText(frame, text, (10, frame.shape[0] - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 4)\n",
        "            cv2.imwrite(\"1.jpg\",frame)\n",
        "\n",
        "            #converts text to speech and plays the audio\n",
        "            speech = gTTS(text = data, lang = 'en', slow = False)\n",
        "            speech.save(\"text.mp3\")\n",
        "            os.system(\"start text.mp3\")\n",
        "            \n",
        "            key = cv2.waitKey(1) & 0xFF\n",
        "            # if the `q` key was pressed, break from the loop\n",
        "            if key == ord(\"q\"):\n",
        "                break\n",
        "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "            writer = cv2.VideoWriter(r\"output.avi\", fourcc, 25,(frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "            (flag, encodedImage) = cv2.imencode(\".jpg\", frame)\n",
        "            yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + \n",
        "                                bytearray(encodedImage) + b'\\r\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "XxEsQBp-nnB7",
        "outputId": "17df039b-7f68-43c0-d2df-9a60f066d88e"
      },
      "source": [
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    return Response(gen(),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1d980b334876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/video_feed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     return Response(gen(),\n\u001b[1;32m      4\u001b[0m                     mimetype='multipart/x-mixed-replace; boundary=frame')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"endpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_url_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;34m\"before the application starts serving requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             )\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36madd_url_rule\u001b[0;34m(self, rule, endpoint, view_func, provide_automatic_options, **options)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                 raise AssertionError(\n\u001b[1;32m   1283\u001b[0m                     \u001b[0;34m\"View function mapping is overwriting an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                     \u001b[0;34m\"existing endpoint function: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 )\n\u001b[1;32m   1286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: View function mapping is overwriting an existing endpoint function: video_feed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve7VopTjnvuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}