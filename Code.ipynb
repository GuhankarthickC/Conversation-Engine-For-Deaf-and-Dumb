{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5DSdedTdaOk"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HvvSVibdaOu",
        "outputId": "54f2a6f6-30c6-42ca-e65c-5a6873a257d9"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwlj_9p8daOv",
        "outputId": "c7f722c1-e0ea-4d77-be03-e60324f98626"
      },
      "source": [
        "x_train = train_datagen.flow_from_directory('gdrive/My Drive/training_set/', target_size=(64,64), batch_size=300, class_mode='categorical',  color_mode = \"grayscale\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15759 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yvVcBEedaOw",
        "outputId": "852fa9c9-e1d4-4230-b0fe-09f574111698"
      },
      "source": [
        "x_train.class_indices"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZJL42YdaOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352bf38d-ebeb-4977-d50b-588538944f16"
      },
      "source": [
        "x_test = test_datagen.flow_from_directory('gdrive/My Drive/test_set/', target_size=(64,64), batch_size=300, class_mode='categorical',  color_mode = \"grayscale\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1310 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZDdsP3rdaOx"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSSswj8VdaOx"
      },
      "source": [
        "model.add(Convolution2D(32, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvfO8BNFdaOy"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnT-eHrMdaOy"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ7-aTy8daOz"
      },
      "source": [
        "model.add(Convolution2D(64, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ1kmBHhdaO0"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wap_36J9daO1"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydP5JJo-daO1"
      },
      "source": [
        "model.add(Convolution2D(128, (3,3), input_shape=(64,64,1), activation = 'relu'))\n",
        "#no. of feature detectors, size of featuredetector, image size, activation function"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj9GZ86FdaO2"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK0UB-qzdaO3"
      },
      "source": [
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8eQ6PhdaO3"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-7at7EPdaO3"
      },
      "source": [
        "model.add(Dense(units=512, activation='relu'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N1qJtZEdaO4"
      },
      "source": [
        "model.add(Dense(units=9, activation='softmax'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eqtQgCVdaO4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76FgFA11daO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c266b7-b241-4d73-c11d-23c6e9ada060"
      },
      "source": [
        "model.fit_generator(x_train, steps_per_epoch=24, epochs=10, validation_data=x_test, validation_steps=40)\n",
        "\n",
        "#steps_per_epoch = no. of train images//batch size"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.5668 - accuracy: 0.4282  WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
            "24/24 [==============================] - 3410s 142s/step - loss: 1.5471 - accuracy: 0.4363 - val_loss: 0.5670 - val_accuracy: 0.8504\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 1354s 56s/step - loss: 0.2721 - accuracy: 0.9119\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 722s 30s/step - loss: 0.1048 - accuracy: 0.9668\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 382s 16s/step - loss: 0.0624 - accuracy: 0.9766\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 211s 9s/step - loss: 0.0432 - accuracy: 0.9867\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 127s 5s/step - loss: 0.0400 - accuracy: 0.9873\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 83s 3s/step - loss: 0.0342 - accuracy: 0.9867\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 64s 3s/step - loss: 0.0205 - accuracy: 0.9933\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 54s 2s/step - loss: 0.0150 - accuracy: 0.9953\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.0295 - accuracy: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f585d1dcd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoMjpE_LdaO5"
      },
      "source": [
        "model.save('aslpng1.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7n3gzbidaO5"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "import numpy as np\r\n",
        "import cv2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp_mzGMZdaO5"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "model=load_model('aslpng1.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCvIowMUdaO5"
      },
      "source": [
        "from skimage.transform import resize\r\n",
        "def detect(frame):\r\n",
        "        img = resize(frame,(64,64,1))\r\n",
        "        img = np.expand_dims(img,axis=0)\r\n",
        "        if(np.max(img)>1):\r\n",
        "            img = img/255.0\r\n",
        "        prediction = model.predict(img)\r\n",
        "        print(prediction)\r\n",
        "        prediction = model.predict_classes(img)\r\n",
        "        print(prediction)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzmFaZ96dCTR",
        "outputId": "69967086-6d79-43a9-dec4-2d0016d0bb02"
      },
      "source": [
        "frame=cv2.imread(r\"gdrive/My Drive/training_set/F/1.png\")\r\n",
        "data = detect(frame)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.32418039e-16 4.34410715e-15 5.48170775e-13 1.10858114e-10\n",
            "  4.96806868e-18 9.99970913e-01 5.03634508e-17 6.03531654e-22\n",
            "  2.91262404e-05]]\n",
            "[5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5HxZkSmpCf",
        "outputId": "09f954ce-a174-48b7-c104-afd67bdcb318"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Downloading https://files.pythonhosted.org/packages/44/31/4494ecac89677d3c839d079363ab655c4751764803ddcd22bcc37f6d32f8/gTTS-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8DlO2Tfmrzd"
      },
      "source": [
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "from keras.models import load_model\r\n",
        "from flask import Flask, render_template, Response\r\n",
        "import tensorflow as tf\r\n",
        "from gtts import gTTS #to convert text to speech\r\n",
        "global graph\r\n",
        "global writer\r\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAoFXsHLmupY",
        "outputId": "e0ea3c9f-cd45-4740-d78f-89f18e8d6a4c"
      },
      "source": [
        "graph = tf.Graph()\r\n",
        "writer = None\r\n",
        "\r\n",
        "model = load_model('aslpng1.h5')\r\n",
        "\r\n",
        "vals = ['A', 'B','C','D','E','F','G','H','I']\r\n",
        "\r\n",
        "app = Flask(__name__)\r\n",
        "\r\n",
        "print(\"[INFO] accessing video stream...\")\r\n",
        "vs = cv2.VideoCapture(0) #triggers the local camera\r\n",
        "\r\n",
        "pred=\"\"\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] accessing video stream...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLbnki7mxue"
      },
      "source": [
        "def detect(frame):\r\n",
        "        img = resize(frame,(64,64,1))\r\n",
        "        img = np.expand_dims(img,axis=0)\r\n",
        "        if(np.max(img)>1):\r\n",
        "            img = img/255.0\r\n",
        "        with graph.as_default():\r\n",
        "                prediction = model.predict_classes(img)\r\n",
        "        print(prediction)\r\n",
        "        pred=vals[prediction[0]]\r\n",
        "        print(pred)\r\n",
        "        return pred\r\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pEY38npnWq5"
      },
      "source": [
        "@app.route('/')\r\n",
        "def index():\r\n",
        "    return render_template('index.html')\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2MfrGHTnbOQ"
      },
      "source": [
        "def gen():\r\n",
        "        while True:\r\n",
        "            # read the next frame from the file\r\n",
        "            (grabbed, frame) = vs.read()\r\n",
        "            \r\n",
        "            # if the frame was not grabbed, then we have reached the end\r\n",
        "            # of the stream\r\n",
        "            if not grabbed:\r\n",
        "                break\r\n",
        "            \r\n",
        "            data = detect(frame)\r\n",
        "            # output frame\r\n",
        "            text = \"It indicates \"+data\r\n",
        "            cv2.putText(frame, text, (10, frame.shape[0] - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 4)\r\n",
        "            cv2.imwrite(\"1.jpg\",frame)\r\n",
        "\r\n",
        "            #converts text to speech and plays the audio\r\n",
        "            speech = gTTS(text = data, lang = 'en', slow = False)\r\n",
        "            speech.save(\"text.mp3\")\r\n",
        "            os.system(\"start text.mp3\")\r\n",
        "            \r\n",
        "            key = cv2.waitKey(1) & 0xFF\r\n",
        "            # if the `q` key was pressed, break from the loop\r\n",
        "            if key == ord(\"q\"):\r\n",
        "                break\r\n",
        "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\r\n",
        "            writer = cv2.VideoWriter(r\"output.avi\", fourcc, 25,(frame.shape[1], frame.shape[0]), True)\r\n",
        "\r\n",
        "            (flag, encodedImage) = cv2.imencode(\".jpg\", frame)\r\n",
        "            yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + \r\n",
        "                                bytearray(encodedImage) + b'\\r\\n')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "XxEsQBp-nnB7",
        "outputId": "17df039b-7f68-43c0-d2df-9a60f066d88e"
      },
      "source": [
        "@app.route('/video_feed')\r\n",
        "def video_feed():\r\n",
        "    return Response(gen(),\r\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    app.run(host='0.0.0.0', debug=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1d980b334876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/video_feed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     return Response(gen(),\n\u001b[1;32m      4\u001b[0m                     mimetype='multipart/x-mixed-replace; boundary=frame')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"endpoint\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_url_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;34m\"before the application starts serving requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             )\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flask/app.py\u001b[0m in \u001b[0;36madd_url_rule\u001b[0;34m(self, rule, endpoint, view_func, provide_automatic_options, **options)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                 raise AssertionError(\n\u001b[1;32m   1283\u001b[0m                     \u001b[0;34m\"View function mapping is overwriting an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                     \u001b[0;34m\"existing endpoint function: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 )\n\u001b[1;32m   1286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: View function mapping is overwriting an existing endpoint function: video_feed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve7VopTjnvuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}